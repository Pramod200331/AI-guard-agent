AI Room Guard Agent

This project implements an intelligent room guard agent that uses your laptop's webcam, microphone, and speakers to monitor a room and respond to potential intruders. The system is designed to activate on a spoken command ("Guard my room"), recognize trusted individuals using face recognition, and engage in an escalating spoken conversation with unrecognized individuals to deter intrusion.

Project Overview
The AI Room Guard integrates several pre-trained AI models—speech recognition, face recognition, text-to-speech, and a conversational language model—into a cohesive system. The agent is built to run in Google Colab, making use of browser-based audio and video recording, and open-source Python libraries for all AI components and trusted individuals are "enrolled" by storing reference photos for face recognition.

Key Features
Voice Activation: The agent listens for a specific spoken command to activate monitoring mode.

Face Recognition: Detects and verifies trusted users using reference photos. Unrecognized faces trigger escalation.

Escalation Dialogue: If an unknown person is detected, the system engages in a three-level spoken escalation: polite inquiry, firm warning, and alarm/threat, with each message generated by a language model and spoken via text-to-speech.

Event Logging: All key events (activation, recognition, escalation) are logged for transparency and audit.

Technologies Used

Speech Recognition: Whisper ASR for robust command detection.

Face Recognition: DeepFace and RetinaFace for face detection and verification.

Text-to-Speech: gTTS for spoken warnings.

Conversational Agent: FLAN-T5 or similar LLM for escalation message generation.

Video/Audio Capture: Browser-based MediaRecorder and getUserMedia APIs for Colab compatibility.

How It Works

Activation: The agent waits for the user to say "Guard my room". Upon detection, it enters guard mode.

Video Capture: The system records a short video of the room using the webcam.

Face Analysis: Faces in the video are compared to enrolled trusted individuals. If only trusted faces are found, the system logs the event and ends the cycle.

Escalation: If an unknown face is detected, the system escalates through three spoken messages, each more urgent, to deter the intruder.


This project emphasizes integration of pre-trained models and robust system design, rather than training new models. All components are open-source and run in a browser environment for accessibility.



For more details on architecture, integration challenges, ethical considerations, and testing results, see the notebook's markdown report and code comments.
